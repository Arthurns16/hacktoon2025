{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c912d0b",
   "metadata": {},
   "source": [
    "\n",
    "# Unified Multiclass Phase Prediction — Cross‑Validated Baselines (LogReg, RF, SVM, XGB, CatBoost)\n",
    "\n",
    "Note: This code is *not* polished. It's very RAM hungry and will stall your computer if you run out. Be warned!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d499b4",
   "metadata": {},
   "source": [
    "\n",
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Choose one:\n",
    "DATASET_PATH = Path('dataset_engineered.csv')\n",
    "\n",
    "# General settings\n",
    "TARGET_COL = 'phase'\n",
    "MIN_CLASS_COUNT = 2\n",
    "TEST_SIZE = 0.20\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# CV & search\n",
    "CV_FOLDS = 5\n",
    "N_ITER = 20\n",
    "N_JOBS = 8\n",
    "OUTPUT_DIR = Path('outputs_unified')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaef5ec",
   "metadata": {},
   "source": [
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159940bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, ConfusionMatrixDisplay,\n",
    "    accuracy_score, balanced_accuracy_score, f1_score\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAVE_XGB = True\n",
    "except Exception:\n",
    "    HAVE_XGB = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    HAVE_CAT = True\n",
    "except Exception:\n",
    "    HAVE_CAT = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf903667",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load & Clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87383ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping rare classes (<2 samples): ['wurtzite', 'rutile-type', 'hexagonal', 'scheelite', 'p2-type layered', 'disilicates', 'columbite', 'pseudocubic t phase structure']\n",
      "Train shape: (591, 276) | Test shape: (148, 276)\n",
      "Numeric cols: 276 | Categorical cols: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET_COL}' not found in {DATASET_PATH}\")\n",
    "\n",
    "# Drop ultra-rare classes\n",
    "vc = df[TARGET_COL].value_counts()\n",
    "rare = vc[vc < MIN_CLASS_COUNT].index.tolist()\n",
    "if len(rare) > 0:\n",
    "    print(f\"Dropping rare classes (<{MIN_CLASS_COUNT} samples): {rare}\")\n",
    "    df = df[~df[TARGET_COL].isin(rare)].copy()\n",
    "\n",
    "# Split\n",
    "y = df[TARGET_COL].astype(str)\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "# Column types\n",
    "numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "print(f\"Train shape: {X_train.shape} | Test shape: {X_test.shape}\")\n",
    "print(f\"Numeric cols: {len(numeric_cols)} | Categorical cols: {len(categorical_cols)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf3d4e",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Shared Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c962ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_tf = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale', StandardScaler(with_mean=False)),\n",
    "])\n",
    "categorical_tf = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=True)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_tf, numeric_cols),\n",
    "        ('cat', categorical_tf, categorical_cols),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=0.3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157cc75",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Helper for Numeric‑label Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f4751b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "\n",
    "class LabelEncodedClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.le_ = LabelEncoder()\n",
    "        self.est_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_enc = self.le_.fit_transform(y)\n",
    "        self.est_ = clone(self.base_estimator)\n",
    "        self.est_.fit(X, y_enc)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_enc = self.est_.predict(X)\n",
    "        return self.le_.inverse_transform(y_enc)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        proba = self.est_.predict_proba(X)\n",
    "        # Columns are in encoded class order; map back\n",
    "        return proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af60a2d3",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Models & Search Spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f507f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "SCORER = make_scorer(f1_score, average='macro')\n",
    "\n",
    "def build_models() -> Dict[str, Any]:\n",
    "    models = {}\n",
    "\n",
    "    # Logistic Regression (OvR)\n",
    "    models['logreg'] = LogisticRegression(\n",
    "        multi_class='ovr', random_state=RANDOM_SEED\n",
    "    )\n",
    "    # Random Forest\n",
    "    models['rf'] = RandomForestClassifier(\n",
    "        n_jobs=-1, random_state=RANDOM_SEED\n",
    "    )\n",
    "    # SVM (RBF)\n",
    "    models['svm'] = SVC(\n",
    "        kernel='rbf', probability=True, random_state=RANDOM_SEED\n",
    "    )\n",
    "    # XGBoost (wrapped)\n",
    "    if HAVE_XGB:\n",
    "        models['xgb'] = LabelEncodedClassifier(\n",
    "            XGBClassifier(\n",
    "                objective='multi:softprob',\n",
    "                tree_method='hist',\n",
    "                random_state=RANDOM_SEED,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "        )\n",
    "    # CatBoost (can handle string labels but we use default sklearn API)\n",
    "    if HAVE_CAT:\n",
    "        models['cat'] = CatBoostClassifier(\n",
    "            random_state=RANDOM_SEED,\n",
    "            allow_writing_files=False,\n",
    "            loss_function='MultiClass',\n",
    "            verbose=False,\n",
    "        )\n",
    "    return models\n",
    "\n",
    "\n",
    "def search_spaces() -> Dict[str, Dict[str, list]]:\n",
    "    spaces = {\n",
    "        'logreg': {\n",
    "            'clf__C': list(np.logspace(-2, 2, 7)),\n",
    "            'clf__penalty': ['l2'],\n",
    "            'clf__solver': ['lbfgs'],\n",
    "            'clf__max_iter': [2000],\n",
    "            'clf__class_weight': [None, 'balanced'],\n",
    "        },\n",
    "        'rf': {\n",
    "            'clf__n_estimators': [200, 300, 500],\n",
    "            'clf__max_depth': [None, 8, 12, 16, 24],\n",
    "            'clf__min_samples_split': [2, 5, 10],\n",
    "            'clf__min_samples_leaf': [1, 2, 4],\n",
    "            'clf__max_features': ['sqrt', 'log2', 0.5],\n",
    "            'clf__class_weight': [None, 'balanced_subsample'],\n",
    "        },\n",
    "        'svm': {\n",
    "            'clf__C': list(np.logspace(-2, 2, 7)),\n",
    "            'clf__gamma': ['scale', 'auto'],\n",
    "            'clf__class_weight': [None, 'balanced'],\n",
    "        },\n",
    "    }\n",
    "    if HAVE_XGB:\n",
    "        spaces['xgb'] = {\n",
    "            'clf__base_estimator__n_estimators': [300, 500, 800],\n",
    "            'clf__base_estimator__learning_rate': [0.03, 0.05, 0.1],\n",
    "            'clf__base_estimator__max_depth': [4, 6, 8],\n",
    "            'clf__base_estimator__subsample': [0.7, 0.9, 1.0],\n",
    "            'clf__base_estimator__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "            'clf__base_estimator__reg_lambda': [0.0, 1.0, 5.0, 10.0],\n",
    "            'clf__base_estimator__reg_alpha': [0.0, 0.5, 1.0],\n",
    "        }\n",
    "    if HAVE_CAT:\n",
    "        spaces['cat'] = {\n",
    "            'clf__depth': [4, 6, 8, 10],\n",
    "            'clf__learning_rate': [0.03, 0.05, 0.1],\n",
    "            'clf__l2_leaf_reg': [1, 3, 5, 9],\n",
    "            'clf__bagging_temperature': [0.0, 0.5, 1.0],\n",
    "            'clf__iterations': [500, 800, 1200],\n",
    "        }\n",
    "    return spaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab351810",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Train‑and‑Evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49395374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "def train_and_eval(model_key: str,\n",
    "                   model,\n",
    "                   param_space: Dict[str, list]) -> Dict[str, Any]:\n",
    "    print(f\"=== {model_key.upper()} ===\")\n",
    "    pipe = Pipeline([('pre', preprocess), ('clf', model)])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_space,\n",
    "        n_iter=N_ITER,\n",
    "        scoring=SCORER,\n",
    "        cv=cv,\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_SEED,\n",
    "        refit=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    best_pipe = search.best_estimator_\n",
    "\n",
    "    # Test evaluation\n",
    "    y_pred = best_pipe.predict(X_test)\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "        'macro_f1': f1_score(y_test, y_pred, average='macro'),\n",
    "        'weighted_f1': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'report': classification_report(y_test, y_pred, output_dict=True),\n",
    "        'best_params': search.best_params_,\n",
    "        'cv_best_score_macro_f1': search.best_score_,\n",
    "    }\n",
    "\n",
    "    # Save artefacts\n",
    "    out_dir = OUTPUT_DIR / model_key\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pd.DataFrame(search.cv_results_).to_csv(out_dir / f\"{model_key}_cv_results.csv\", index=False)\n",
    "    (out_dir / f\"{model_key}_test_metrics.json\").write_text(json.dumps(metrics, indent=2))\n",
    "\n",
    "    # Confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax, xticks_rotation=90, colorbar=False)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_dir / f\"{model_key}_confusion_matrix.png\", dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Save fitted end-to-end pipeline\n",
    "    joblib.dump(best_pipe, out_dir / f\"{model_key}_pipeline.pkl\")\n",
    "\n",
    "    print(json.dumps({k: v for k, v in metrics.items() if k not in ['report']}, indent=2))\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c399f",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Run All Models\n",
    "We train and tune: **logreg**, **rf**, **svm**, and (if installed) **xgb**, **cat**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f0d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOGREG ===\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "{\n",
      "  \"accuracy\": 0.6959459459459459,\n",
      "  \"balanced_accuracy\": 0.36437096577761535,\n",
      "  \"macro_f1\": 0.3816873112039244,\n",
      "  \"weighted_f1\": 0.6413896373571559,\n",
      "  \"best_params\": {\n",
      "    \"clf__solver\": \"lbfgs\",\n",
      "    \"clf__penalty\": \"l2\",\n",
      "    \"clf__max_iter\": 2000,\n",
      "    \"clf__class_weight\": null,\n",
      "    \"clf__C\": 0.01\n",
      "  },\n",
      "  \"cv_best_score_macro_f1\": NaN\n",
      "}\n",
      "=== RF ===\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{\n",
      "  \"accuracy\": 0.7972972972972973,\n",
      "  \"balanced_accuracy\": 0.5691694068931921,\n",
      "  \"macro_f1\": 0.5946413493627115,\n",
      "  \"weighted_f1\": 0.7654795388348019,\n",
      "  \"best_params\": {\n",
      "    \"clf__n_estimators\": 300,\n",
      "    \"clf__min_samples_split\": 5,\n",
      "    \"clf__min_samples_leaf\": 1,\n",
      "    \"clf__max_features\": \"sqrt\",\n",
      "    \"clf__max_depth\": 16,\n",
      "    \"clf__class_weight\": null\n",
      "  },\n",
      "  \"cv_best_score_macro_f1\": NaN\n",
      "}\n",
      "=== SVM ===\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{\n",
      "  \"accuracy\": 0.6283783783783784,\n",
      "  \"balanced_accuracy\": 0.21663013031299475,\n",
      "  \"macro_f1\": 0.18567011104714312,\n",
      "  \"weighted_f1\": 0.5147305614564216,\n",
      "  \"best_params\": {\n",
      "    \"clf__gamma\": \"auto\",\n",
      "    \"clf__class_weight\": null,\n",
      "    \"clf__C\": 0.21544346900318834\n",
      "  },\n",
      "  \"cv_best_score_macro_f1\": NaN\n",
      "}\n",
      "=== XGB ===\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = build_models()\n",
    "spaces = search_spaces()\n",
    "\n",
    "results = {}\n",
    "for key, mdl in models.items():\n",
    "    try:\n",
    "        res = train_and_eval(key, mdl, spaces[key])\n",
    "        results[key] = res\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Skipping {key}: {e}\")\n",
    "\n",
    "\n",
    "summary_rows = []\n",
    "for k, r in results.items():\n",
    "    summary_rows.append({\n",
    "        'model': k,\n",
    "        'cv_macro_f1_best_mean': r.get('cv_best_score_macro_f1', None),\n",
    "        'test_macro_f1': r['macro_f1'],\n",
    "        'test_weighted_f1': r['weighted_f1'],\n",
    "        'test_accuracy': r['accuracy'],\n",
    "    })\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values('test_macro_f1', ascending=False)\n",
    "summary_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
