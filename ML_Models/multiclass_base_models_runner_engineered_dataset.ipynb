{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac062ed",
   "metadata": {},
   "source": [
    "# Multiclass Models Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4871b",
   "metadata": {},
   "source": [
    "This notebook needs: \n",
    "* raw CSV at DATA_PATH with target column named phase. \n",
    "\n",
    "This notebook automatically:\n",
    "* encodes categoricals (one-hot),\n",
    "* preserves a mapping of class labels,\n",
    "* calls each model script,\n",
    "* saves summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e10b1",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd699e",
   "metadata": {},
   "source": [
    "### Imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db3a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import inspect\n",
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from utils_ml import ensure_dirs\n",
    "\n",
    "# Model runners\n",
    "from rf_model_base import run_random_forest\n",
    "from xgb_model_base import run_xgboost\n",
    "from catboost_model_base import run_catboost\n",
    "from logreg_model_base import run_logreg\n",
    "from svm_model_base import run_svm_rbf\n",
    "\n",
    "\n",
    "DATA_PATH = \"data/dataset_deduplicated_engineered.csv\"   \n",
    "MODEL_DIR = \"./data/engineered_base/eng_base_best_ML_pkl\"\n",
    "PERF_DIR  = \"./data/engineered_base/eng_base_ML_performance_summary\"\n",
    "\n",
    "ensure_dirs(MODEL_DIR, PERF_DIR)\n",
    "print(\"Setup complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e0654",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be48722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 276 numeric and 0 categorical features.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "assert \"phase\" in df.columns, \"Target column 'phase' not found.\"\n",
    "\n",
    "y_raw = df[\"phase\"].astype(str)\n",
    "X_raw = df.drop(columns=[\"phase\"])\n",
    "\n",
    "# Identify column types\n",
    "cat_cols = X_raw.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "num_cols = X_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Detected {len(num_cols)} numeric and {len(cat_cols)} categorical features.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14240296",
   "metadata": {},
   "source": [
    "### Train/Valid/Test split (stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa880594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_train_valid_test_split(\n",
    "    X, y, *, test_size=0.2, valid_size=0.2, min_per_class=3, random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Manual stratified 3-way split that avoids sklearn's '>=2 per class per split' constraint.\n",
    "    - Pre-merges ultra-rare classes (< min_per_class) into 'Other'.\n",
    "    - Ensures at least 1 sample per class in each split whenever possible.\n",
    "    Returns: X_tr, X_va, X_te, y_tr, y_va, y_te, merged_flag\n",
    "    Works with X as DataFrame/ndarray; y as array-like/Series.\n",
    "    \"\"\"\n",
    "    # --- normalize inputs ---\n",
    "    is_df = isinstance(X, pd.DataFrame)\n",
    "    y = pd.Series(y).astype(str)\n",
    "    rs = RandomState(random_state)\n",
    "\n",
    "    # --- pre-merge rare classes ---\n",
    "    vc = y.value_counts()\n",
    "    rare = vc[vc < min_per_class].index.tolist()\n",
    "    merged_flag = False\n",
    "    if rare:\n",
    "        print(f\"Merging rare classes into 'Other': {rare}\")\n",
    "        y = y.where(~y.isin(rare), other=\"Other\")\n",
    "        merged_flag = True\n",
    "\n",
    "    # if 'Other' has only 1 sample, drop it (can't be split sensibly)\n",
    "    if (y == \"Other\").sum() == 1:\n",
    "        print(\"Dropping single-sample 'Other' to enable splitting.\")\n",
    "        keep = ~(y == \"Other\")\n",
    "        X = X.loc[keep] if is_df else X[keep]\n",
    "        y = y.loc[keep]\n",
    "\n",
    "    n = len(y)\n",
    "    n_valid = max(1, int(round(valid_size * n)))\n",
    "    n_test  = max(1, int(round(test_size * n)))\n",
    "    # keep at least 1 sample for train\n",
    "    n_train = n - n_valid - n_test\n",
    "    if n_train < 1:\n",
    "        # borrow from the larger of valid/test\n",
    "        take_from_valid = n_valid >= n_test\n",
    "        if take_from_valid and n_valid > 1:\n",
    "            n_valid -= 1\n",
    "        elif n_test > 1:\n",
    "            n_test -= 1\n",
    "        n_train = n - n_valid - n_test\n",
    "        if n_train < 1:\n",
    "            # final fallback\n",
    "            n_train, n_valid, n_test = max(1, n-2), 1, 1\n",
    "\n",
    "    # --- per-class allocation ---\n",
    "    idx = np.arange(n)\n",
    "    if is_df:\n",
    "        idx = X.index.to_numpy()\n",
    "\n",
    "    train_idx = []\n",
    "    valid_idx = []\n",
    "    test_idx  = []\n",
    "\n",
    "    for cls, cls_count in y.value_counts().items():\n",
    "        cls_indices = idx[(y == cls).to_numpy()]\n",
    "        rs.shuffle(cls_indices)\n",
    "\n",
    "        # proportional targets\n",
    "        v = int(round(valid_size * cls_count))\n",
    "        t = int(round(test_size  * cls_count))\n",
    "        # ensure at least 1 where possible\n",
    "        v = min(max(1 if cls_count >= 3 else 0, v), cls_count)  # allow 0 if class size < 3\n",
    "        t = min(max(1 if cls_count >= 3 else 0, t), cls_count - v)\n",
    "\n",
    "        r = cls_count - v - t\n",
    "        if cls_count >= 3:\n",
    "            if r < 1:\n",
    "                # borrow from the larger of v/t\n",
    "                if v > t and v > 1:\n",
    "                    v -= 1\n",
    "                elif t > 1:\n",
    "                    t -= 1\n",
    "                r = cls_count - v - t\n",
    "                if r < 1:\n",
    "                    # last resort: set v=t=1\n",
    "                    v, t, r = 1, 1, cls_count - 2\n",
    "        else:\n",
    "            # for tiny classes (size 1 or 2), just push all to train\n",
    "            v, t, r = 0, 0, cls_count\n",
    "\n",
    "        # slice\n",
    "        cls_valid = cls_indices[:v]\n",
    "        cls_test  = cls_indices[v:v+t]\n",
    "        cls_train = cls_indices[v+t:]\n",
    "\n",
    "        valid_idx.append(cls_valid)\n",
    "        test_idx.append(cls_test)\n",
    "        train_idx.append(cls_train)\n",
    "\n",
    "    train_idx = np.concatenate(train_idx) if train_idx else np.array([], dtype=int)\n",
    "    valid_idx = np.concatenate(valid_idx) if valid_idx else np.array([], dtype=int)\n",
    "    test_idx  = np.concatenate(test_idx)  if test_idx  else np.array([], dtype=int)\n",
    "\n",
    "    # If global counts drifted from targets, that's ok; we guaranteed per-class feasibility.\n",
    "\n",
    "    # --- build splits ---\n",
    "    def take(Xin, ind):\n",
    "        return Xin.loc[ind] if is_df else Xin[np.isin(idx, ind)]\n",
    "\n",
    "    X_tr = take(X, train_idx)\n",
    "    X_va = take(X, valid_idx)\n",
    "    X_te = take(X, test_idx)\n",
    "    y_tr = y.loc[train_idx]\n",
    "    y_va = y.loc[valid_idx]\n",
    "    y_te = y.loc[test_idx]\n",
    "\n",
    "    # sanity prints (optional)\n",
    "    print(\"Final per-split counts:\", len(y_tr), len(y_va), len(y_te))\n",
    "    print(\"Min per-class (train/valid/test):\",\n",
    "          y_tr.value_counts().min() if len(y_tr) else 0,\n",
    "          y_va.value_counts().min() if len(y_va) else 0,\n",
    "          y_te.value_counts().min() if len(y_te) else 0)\n",
    "\n",
    "    return X_tr, X_va, X_te, y_tr, y_va, y_te, merged_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f08bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging rare classes into 'Other': ['layered rock salt', 'double perovskite', 'c-type', 'monosilicates', 'tetragonal', 'wurtzite', 'rutile-type', 'hexagonal', 'scheelite', 'p2-type layered', 'disilicates', 'columbite', 'pseudocubic t phase structure']\n",
      "Final per-split counts: 444 150 150\n",
      "Min per-class (train/valid/test): 1 1 1\n",
      "Merged rare classes into 'Other'? True\n",
      "Class counts (train/valid/test):\n",
      "phase\n",
      "spinel                         134\n",
      "cubic perovskite                73\n",
      "fluorite                        62\n",
      "multiphase                      44\n",
      "pyrochlore                      24\n",
      "rock salt                       19\n",
      "orthorhombic perovskite         13\n",
      "magnetoplumbite                 11\n",
      "amorphous                       10\n",
      "Other                           10\n",
      "monoclinic                      10\n",
      "bixbyite                         8\n",
      "tetragonal perovskite            8\n",
      "layered ruddlesdenâpopper      5\n",
      "garnet                           5\n",
      "rutile                           4\n",
      "o3-type layered                  3\n",
      "cubic                            1\n",
      "Name: count, dtype: int64 \n",
      " phase\n",
      "spinel                         45\n",
      "cubic perovskite               25\n",
      "fluorite                       20\n",
      "multiphase                     14\n",
      "pyrochlore                      8\n",
      "rock salt                       7\n",
      "orthorhombic perovskite         5\n",
      "Other                           4\n",
      "amorphous                       4\n",
      "monoclinic                      4\n",
      "magnetoplumbite                 3\n",
      "bixbyite                        3\n",
      "tetragonal perovskite           2\n",
      "rutile                          2\n",
      "layered ruddlesdenâpopper     1\n",
      "garnet                          1\n",
      "o3-type layered                 1\n",
      "cubic                           1\n",
      "Name: count, dtype: int64 \n",
      " phase\n",
      "spinel                         45\n",
      "cubic perovskite               25\n",
      "fluorite                       20\n",
      "multiphase                     14\n",
      "pyrochlore                      8\n",
      "rock salt                       7\n",
      "orthorhombic perovskite         5\n",
      "Other                           4\n",
      "amorphous                       4\n",
      "monoclinic                      4\n",
      "magnetoplumbite                 3\n",
      "bixbyite                        3\n",
      "tetragonal perovskite           2\n",
      "rutile                          2\n",
      "layered ruddlesdenâpopper     1\n",
      "garnet                          1\n",
      "o3-type layered                 1\n",
      "cubic                           1\n",
      "Name: count, dtype: int64\n",
      "Shapes: (444, 276) (150, 276) (150, 276)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, X_valid_raw, X_test_raw, y_train, y_valid, y_test, merged = stratified_train_valid_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, valid_size=0.2, min_per_class=3, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Merged rare classes into 'Other'?\", merged)\n",
    "print(\"Class counts (train/valid/test):\")\n",
    "print(y_train.value_counts(), \"\\n\", y_valid.value_counts(), \"\\n\", y_test.value_counts())\n",
    "print(\"Shapes:\", X_train_raw.shape, X_valid_raw.shape, X_test_raw.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e2f20",
   "metadata": {},
   "source": [
    "### Preprocessing: Impute + One-Hot for categoricals, Impute for numerics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c133acf",
   "metadata": {},
   "source": [
    "One-hot encodes all categorical features once (fit on train), passes through numerics. Linear/SVM add scaling internally; trees use the one-hot features as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954db073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [np.str_('Other'), np.str_('amorphous'), np.str_('bixbyite'), np.str_('cubic'), np.str_('cubic perovskite'), np.str_('fluorite'), np.str_('garnet'), np.str_('layered ruddlesdenâ\\x80\\x93popper'), np.str_('magnetoplumbite'), np.str_('monoclinic'), np.str_('multiphase'), np.str_('o3-type layered'), np.str_('orthorhombic perovskite'), np.str_('pyrochlore'), np.str_('rock salt'), np.str_('rutile'), np.str_('spinel'), np.str_('tetragonal perovskite')]\n",
      "Preprocessing complete. Shapes -> train: (444, 274) valid: (150, 274) test: (150, 274)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['molar_vol_cov' 'molar_vol_min_to_max_ratio']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['molar_vol_cov' 'molar_vol_min_to_max_ratio']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['molar_vol_cov' 'molar_vol_min_to_max_ratio']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['molar_vol_cov' 'molar_vol_min_to_max_ratio']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- OneHotEncoder: version-safe 'sparse_output' vs 'sparse' ---\n",
    "if \"sparse_output\" in inspect.signature(OneHotEncoder).parameters:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "else:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "\n",
    "# Pipelines per type (fit on TRAIN only to avoid leakage)\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", ohe),\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", cat_pipe, cat_cols),\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=1.0,   # keep output sparse when beneficial\n",
    ")\n",
    "\n",
    "# Fit on training data only\n",
    "preprocess.fit(X_train_raw)\n",
    "\n",
    "def transform_and_get_feature_names(X_df):\n",
    "    Xtx = preprocess.transform(X_df)\n",
    "    # Build feature names\n",
    "    if cat_cols:\n",
    "        cat_names = preprocess.named_transformers_[\"cat\"].named_steps[\"ohe\"].get_feature_names_out(cat_cols)\n",
    "    else:\n",
    "        cat_names = np.array([])\n",
    "    feat_names = np.concatenate([cat_names, np.array(num_cols)])\n",
    "    return Xtx, feat_names\n",
    "\n",
    "X_train, feature_names = transform_and_get_feature_names(X_train_raw)\n",
    "X_valid, _ = transform_and_get_feature_names(X_valid_raw)\n",
    "X_test,  _ = transform_and_get_feature_names(X_test_raw)\n",
    "\n",
    "# Class labels (string) — unchanged\n",
    "class_labels = unique_labels(y_train, y_valid, y_test)\n",
    "print(f\"Classes: {list(class_labels)}\")\n",
    "print(\"Preprocessing complete. Shapes ->\",\n",
    "      \"train:\", X_train.shape, \"valid:\", X_valid.shape, \"test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43609c9a",
   "metadata": {},
   "source": [
    "### Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d686545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied Standard scaling to X_train/valid/test. Saved scaler -> ./data/engineered_base/eng_base_best_ML_pkl\\eng_global_std_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "SCALER_PATH = os.path.join(MODEL_DIR, \"eng_global_std_scaler.pkl\")\n",
    "\n",
    "scaler = StandardScaler()          # scales each feature by its max |value| on TRAIN\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# (Optional) save for inference pipelines\n",
    "dump(scaler, SCALER_PATH)\n",
    "print(\"Applied Standard scaling to X_train/valid/test. Saved scaler ->\", SCALER_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5267dd",
   "metadata": {},
   "source": [
    "### Encode target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee69ae8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_index</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>amorphous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bixbyite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cubic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cubic perovskite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_index        class_name\n",
       "0            0             Other\n",
       "1            1         amorphous\n",
       "2            2          bixbyite\n",
       "3            3             cubic\n",
       "4            4  cubic perovskite"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder().fit(pd.concat([y_train, y_valid, y_test]).astype(str))\n",
    "y_train_enc = le.transform(y_train.astype(str))\n",
    "y_valid_enc = le.transform(y_valid.astype(str))\n",
    "y_test_enc  = le.transform(y_test.astype(str))\n",
    "\n",
    "# numeric class labels 0..K-1 for metrics & models\n",
    "class_labels = np.arange(len(le.classes_))\n",
    "\n",
    "# (optional) save the mapping for later interpretability\n",
    "mapping = pd.DataFrame({\"class_index\": class_labels, \"class_name\": le.classes_})\n",
    "mapping.to_csv(\"data/engineered_base/eng_base_ML_performance_summary/label_mapping.csv\", index=False)\n",
    "mapping.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df780d7e",
   "metadata": {},
   "source": [
    "## Run all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e4794",
   "metadata": {},
   "source": [
    "**CV & grids:** 3-fold CV with compact grids keeps runtime reasonable but still tunes the big levers.\n",
    "\n",
    "**Refit policy:** Each script tunes on the train split (via CV), evaluates the tuned model on the validation split, then refits the best params on train+validation and reports test metrics in the final summary. The saved .pkl is this refit model (best performance for deployment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616bf4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "Using 200 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.498e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.700e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.933e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.399e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.439e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.439e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.526e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  1%|▏         | 1/80 [00:00<00:45,  1.73it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.844e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.757e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.917e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.168e-04, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.712e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=9.931e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.615e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.543e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.828e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.736e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.186e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.009e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.043e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  2%|▎         | 2/80 [00:01<00:43,  1.78it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.198e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.716e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  4%|▍         | 3/80 [00:01<00:44,  1.73it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.023e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.609e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.655e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.786e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.967e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.878e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.939e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.939e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.939e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.939e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.464e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.021e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.179e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.191e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.191e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.256e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.320e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.317e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.160e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.160e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.145e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  5%|▌         | 4/80 [00:02<00:44,  1.72it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.706e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.494e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.986e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.599e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.784e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  6%|▋         | 5/80 [00:02<00:43,  1.71it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.829e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.354e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.274e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.119e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.770e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.552e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.450e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.725e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.725e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.303e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.303e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.470e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.470e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.975e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.975e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.983e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.109e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.974e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.339e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.350e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.155e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  8%|▊         | 6/80 [00:03<00:43,  1.70it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.601e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.519e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.906e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.429e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.977e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.113e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.950e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.088e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.088e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.907e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.906e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.573e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.073e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.558e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.221e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.221e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.490e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.882e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "  9%|▉         | 7/80 [00:04<00:42,  1.70it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.395e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.573e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 10%|█         | 8/80 [00:04<00:42,  1.70it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.089e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.037e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.621e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 11%|█▏        | 9/80 [00:05<00:41,  1.71it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.587e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.670e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.795e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.785e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.292e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.749e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.749e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.782e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.782e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.762e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.584e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.266e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.526e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=8.140e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.054e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.610e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.005e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.005e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.702e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 10/80 [00:05<00:41,  1.71it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.866e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.421e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.167e-01, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.392e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.392e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.392e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.263e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.263e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.944e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.938e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.937e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.158e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.032e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.515e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.515e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.161e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.746e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.746e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.620e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.607e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.812e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.172e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.847e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 14%|█▍        | 11/80 [00:06<00:39,  1.74it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.344e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.172e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.641e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.296e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.130e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.133e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.752e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.329e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.559e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.384e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.722e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.094e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.214e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.214e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.705e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.705e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.842e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.503e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.409e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.982e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.982e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 15%|█▌        | 12/80 [00:06<00:39,  1.73it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.153e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.632e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.397e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.482e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.596e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.280e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 16%|█▋        | 13/80 [00:07<00:38,  1.73it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.373e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.312e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.312e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.755e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.217e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.217e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.217e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.140e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.012e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.640e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.208e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.194e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.417e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.862e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.863e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.354e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.708e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.128e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.686e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.181e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.482e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 18%|█▊        | 14/80 [00:08<00:37,  1.76it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.768e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.719e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.006e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.795e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.578e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.146e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.146e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.066e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.607e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.585e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.376e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.557e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.482e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.440e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.439e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.244e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.493e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.478e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.033e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.927e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.927e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.392e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.392e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.322e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 19%|█▉        | 15/80 [00:08<00:36,  1.77it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.861e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.455e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.889e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.570e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.561e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.176e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.532e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.983e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.474e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.296e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.215e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.810e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.810e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.810e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.099e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 20%|██        | 16/80 [00:09<00:36,  1.77it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.353e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.233e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.546e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.437e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.700e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.700e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.257e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.372e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.616e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.938e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.816e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 21%|██▏       | 17/80 [00:09<00:35,  1.76it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.399e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.449e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.227e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.799e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.302e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.899e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.672e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.672e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.450e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.446e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.156e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.083e-05, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.302e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.554e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 22%|██▎       | 18/80 [00:10<00:35,  1.73it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.339e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.135e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.849e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.947e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.785e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.052e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 24%|██▍       | 19/80 [00:11<00:36,  1.65it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 26%|██▋       | 21/80 [00:12<00:37,  1.56it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 28%|██▊       | 22/80 [00:13<00:37,  1.56it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.863e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.435e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.435e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.435e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.038e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.298e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.607e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.962e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.747e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.498e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.498e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.642e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.246e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.420e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.688e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.939e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.327e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 29%|██▉       | 23/80 [00:13<00:35,  1.62it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.072e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.641e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.481e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.317e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.232e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.230e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 30%|███       | 24/80 [00:14<00:33,  1.68it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.225e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.520e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.520e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.414e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.608e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.676e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.667e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.216e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.208e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.171e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.171e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.226e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.390e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.390e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.634e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.458e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.106e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 31%|███▏      | 25/80 [00:14<00:31,  1.74it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.319e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.026e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.166e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.600e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.594e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.567e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.557e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=9.337e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.669e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.669e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.118e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.467e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.088e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.380e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.898e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.898e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.069e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.069e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.069e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.286e-04, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.641e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.150e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.143e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.143e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.562e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.410e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 32%|███▎      | 26/80 [00:15<00:33,  1.60it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.339e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.339e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.173e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 34%|███▍      | 27/80 [00:16<00:37,  1.42it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.715e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.337e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.786e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.313e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 35%|███▌      | 28/80 [00:17<00:38,  1.35it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.391e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.349e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.897e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.879e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.056e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 36%|███▋      | 29/80 [00:17<00:38,  1.31it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.817e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.817e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.409e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.409e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.776e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.776e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.544e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.213e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.213e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.104e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.462e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.462e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.000e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.000e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.335e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.938e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.711e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.969e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.677e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.183e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.171e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 30/80 [00:18<00:36,  1.38it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.001e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.528e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.630e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.491e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.619e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.155e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.155e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.155e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.020e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.620e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.118e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.055e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.616e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.993e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.993e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.391e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.391e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.308e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.308e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.371e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 39%|███▉      | 31/80 [00:19<00:35,  1.39it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.501e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.036e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.362e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.466e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.411e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.874e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.498e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.498e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.498e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.003e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.481e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.481e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.481e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.007e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.491e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.491e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.489e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.489e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 40%|████      | 32/80 [00:20<00:36,  1.31it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.164e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.164e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.028e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.028e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.568e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.180e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.102e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.843e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.404e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.421e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.984e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.844e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 41%|████▏     | 33/80 [00:21<00:37,  1.25it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.322e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.610e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.610e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.183e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.830e-05, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.809e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.800e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.590e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.593e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.229e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.368e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.946e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.501e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 42%|████▎     | 34/80 [00:21<00:37,  1.22it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.928e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.642e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.360e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.571e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.494e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.786e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.328e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.530e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.105e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.552e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.552e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.552e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.885e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.929e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.406e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.423e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 44%|████▍     | 35/80 [00:22<00:35,  1.28it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.457e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.146e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.186e-04, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.087e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.607e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.204e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.204e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.143e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.996e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.959e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.091e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.072e-01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.072e-01, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.529e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 45%|████▌     | 36/80 [00:23<00:31,  1.39it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.352e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.352e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.638e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.288e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.137e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.945e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.073e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.073e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.852e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.852e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.168e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 46%|████▋     | 37/80 [00:23<00:29,  1.48it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.129e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.236e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.961e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.879e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.335e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.059e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.663e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.663e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=9.614e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.999e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.897e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.547e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.245e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.994e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.130e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.789e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.789e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.163e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.379e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.865e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.636e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.901e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.553e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.732e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.242e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.015e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.679e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.151e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.498e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.498e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.249e-05, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.249e-05, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.249e-05, with an active set of 7 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.249e-05, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.548e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 48%|████▊     | 38/80 [00:24<00:28,  1.50it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 49%|████▉     | 39/80 [00:25<00:27,  1.52it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.754e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.038e-04, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.193e-05, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.190e-05, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.012e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.761e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.336e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.984e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.087e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.087e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.974e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.134e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.103e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.243e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.125e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.378e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.378e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.126e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 50%|█████     | 40/80 [00:25<00:25,  1.55it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.091e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.091e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.045e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.088e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.791e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.936e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.229e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.007e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.182e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.182e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.662e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.755e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.561e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.302e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.302e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 51%|█████▏    | 41/80 [00:26<00:24,  1.61it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.947e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.153e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.153e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.222e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.162e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.019e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.144e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.906e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 52%|█████▎    | 42/80 [00:26<00:23,  1.64it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.933e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.749e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.666e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.067e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.067e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.883e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.738e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.395e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.279e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 54%|█████▍    | 43/80 [00:27<00:22,  1.67it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.507e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.342e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.265e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 55%|█████▌    | 44/80 [00:27<00:21,  1.69it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.808e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.271e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.996e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.086e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.984e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.684e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 56%|█████▋    | 45/80 [00:28<00:20,  1.71it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.991e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.201e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.157e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.792e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.635e-04, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.817e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.174e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.538e-04, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.436e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.321e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.426e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 57%|█████▊    | 46/80 [00:29<00:19,  1.72it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.823e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.661e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 59%|█████▉    | 47/80 [00:29<00:19,  1.68it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.937e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.163e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=9.245e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.203e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.017e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.009e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.239e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.551e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.640e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.640e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.530e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.530e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 60%|██████    | 48/80 [00:30<00:18,  1.72it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.984e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.492e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.283e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.701e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.359e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.328e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.693e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.588e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.898e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.821e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.897e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 61%|██████▏   | 49/80 [00:30<00:17,  1.74it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.268e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.917e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.383e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.331e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.184e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 62%|██████▎   | 50/80 [00:31<00:17,  1.73it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.641e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.983e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.465e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.465e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.409e-05, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.205e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.205e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.799e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.799e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.399e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.399e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.323e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.457e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.953e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.176e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.882e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.581e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.712e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.671e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.391e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.232e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.332e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=9.199e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.600e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 64%|██████▍   | 51/80 [00:32<00:16,  1.72it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.232e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.533e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.845e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.972e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.133e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.057e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.320e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.356e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.255e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.112e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.112e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.163e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.945e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.538e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.382e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.769e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.237e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 65%|██████▌   | 52/80 [00:32<00:16,  1.73it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.038e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.065e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.650e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.048e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.389e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.334e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.835e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.923e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.418e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.274e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.545e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.917e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 66%|██████▋   | 53/80 [00:33<00:16,  1.69it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.077e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.690e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.690e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.553e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.553e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=9.927e-04, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.675e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.675e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.393e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.436e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.298e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.962e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.821e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.821e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.821e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 68%|██████▊   | 54/80 [00:33<00:15,  1.71it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.878e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.703e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.852e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.287e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.286e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.868e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.864e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.209e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.127e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.540e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.540e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.611e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.825e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 69%|██████▉   | 55/80 [00:34<00:14,  1.70it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=8.842e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.370e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.009e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.192e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.192e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.192e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.421e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.322e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.176e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.751e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 70%|███████   | 56/80 [00:35<00:14,  1.60it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.150e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.402e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.684e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.605e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 71%|███████▏  | 57/80 [00:35<00:14,  1.61it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.352e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.330e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.080e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 72%|███████▎  | 58/80 [00:36<00:13,  1.65it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.457e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.424e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.424e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.424e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.636e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.289e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.723e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.723e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 74%|███████▍  | 59/80 [00:36<00:12,  1.67it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.682e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.831e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.978e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.624e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.580e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.294e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 60/80 [00:37<00:12,  1.65it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.284e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.459e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.321e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.088e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.298e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.298e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.264e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.244e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.222e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.125e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.564e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 76%|███████▋  | 61/80 [00:38<00:11,  1.64it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.119e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.564e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.595e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.455e-01, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.366e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.473e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.473e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 78%|███████▊  | 62/80 [00:38<00:10,  1.66it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.168e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.873e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.368e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.584e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.584e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.509e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.509e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.967e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.505e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.333e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.333e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.333e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.166e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.166e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.166e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.491e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.222e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.222e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.674e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.569e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.677e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.649e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.375e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.304e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.297e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.137e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.148e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.550e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.550e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.843e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.583e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.404e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.792e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.022e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.048e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.037e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.023e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.023e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 79%|███████▉  | 63/80 [00:39<00:10,  1.67it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.622e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.811e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.292e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.874e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.354e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.354e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.326e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.549e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.237e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.694e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.354e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.089e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.188e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.188e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.131e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=9.647e-04, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.823e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.397e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.990e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.990e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.990e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.038e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.038e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.135e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.135e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.993e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.993e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.565e-02, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.422e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.422e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.962e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.287e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.145e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.145e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 80%|████████  | 64/80 [00:39<00:09,  1.70it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.848e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.678e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.142e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.775e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.774e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.315e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.549e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.306e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.869e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.950e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.345e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.279e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 81%|████████▏ | 65/80 [00:40<00:08,  1.72it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.296e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.919e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.196e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.662e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.313e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.243e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.879e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.218e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.158e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.008e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 82%|████████▎ | 66/80 [00:40<00:07,  1.77it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.900e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.863e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.555e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.382e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.706e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.609e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.251e-01, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 84%|████████▍ | 67/80 [00:41<00:07,  1.80it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.340e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.852e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.698e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.698e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 85%|████████▌ | 68/80 [00:42<00:06,  1.82it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.920e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.327e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=8.301e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.657e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.502e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.502e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 86%|████████▋ | 69/80 [00:42<00:05,  1.84it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.253e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 70/80 [00:43<00:05,  1.83it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.016e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.004e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.004e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.292e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.880e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=7.464e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.286e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.923e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.923e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.923e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.923e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 89%|████████▉ | 71/80 [00:43<00:04,  1.82it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.948e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.733e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.249e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.124e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.124e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.124e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.295e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.270e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.709e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      " 90%|█████████ | 72/80 [00:44<00:04,  1.85it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.386e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.839e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.238e-04, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.558e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.120e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.120e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.965e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.965e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.915e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.915e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.915e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.903e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.903e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.903e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.417e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.417e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.417e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.796e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.392e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.691e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.598e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.758e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.159e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.115e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.624e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.941e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.941e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.954e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 91%|█████████▏| 73/80 [00:44<00:03,  1.86it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=7.466e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.851e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.565e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.447e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.810e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.699e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.699e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.519e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.631e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.231e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.167e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.036e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.840e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.433e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.433e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.433e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 92%|█████████▎| 74/80 [00:45<00:03,  1.87it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.795e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.710e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.397e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.992e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.992e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.992e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=3.037e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.012e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.675e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=7.278e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.384e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.944e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.426e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.624e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=9.940e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 94%|█████████▍| 75/80 [00:45<00:02,  1.88it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.256e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.086e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 95%|█████████▌| 76/80 [00:46<00:02,  1.90it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.129e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.118e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.092e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.912e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.618e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.056e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.701e-04, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.591e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.631e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.069e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.069e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.267e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.137e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.999e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.906e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.963e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=6.169e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.555e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.137e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.583e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.583e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=9.031e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 96%|█████████▋| 77/80 [00:46<00:01,  1.89it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.507e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.237e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 98%|█████████▊| 78/80 [00:47<00:01,  1.89it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.737e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.422e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.413e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.545e-05, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.582e-05, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.571e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.571e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.409e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.325e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.193e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.193e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.193e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.901e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.289e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.538e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.800e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.103e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=5.478e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.350e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.060e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.060e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.060e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=7.857e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.691e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.486e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      " 99%|█████████▉| 79/80 [00:47<00:00,  1.90it/s]d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.322e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.193e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.375e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.375e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.202e-04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.600e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\shap\\explainers\\_kernel.py:708: UserWarning: Linear regression equation is singular, a least squares solutions is used instead.\n",
      "To avoid this situation and get a regular matrix do one of the following:\n",
      "1) turn up the number of samples,\n",
      "2) turn up the L1 regularization with num_features(N) where N is less than the number of samples,\n",
      "3) group features together to reduce the number of inputs that need to be explained.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.199e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.095e-04, with an active set of 8 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.465e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.131e-03, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.240e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.895e-03, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=1.053e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.930e-04, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.758e-04, with an active set of 6 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.830e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.198e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.329e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "d:\\OnLine Courses\\LLMs for Materials and Chemistry Hackaton\\LLMHackathon\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.509e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "100%|██████████| 80/80 [00:48<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models trained and evaluated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_metrics = []\n",
    "all_top10 = []\n",
    "\n",
    "# Tree-based ensembles\n",
    "m, t = run_random_forest(X_train, y_train_enc, X_valid, y_valid_enc, X_test, y_test_enc,\n",
    "                         feature_names, class_labels, MODEL_DIR)\n",
    "all_metrics.append(m); all_top10.append(t)\n",
    "\n",
    "m, t = run_xgboost(X_train, y_train_enc, X_valid, y_valid_enc, X_test, y_test_enc,\n",
    "                   feature_names, class_labels, MODEL_DIR)\n",
    "all_metrics.append(m); all_top10.append(t)\n",
    "\n",
    "m, t = run_catboost(X_train, y_train_enc, X_valid, y_valid_enc, X_test, y_test_enc,\n",
    "                    feature_names, class_labels, MODEL_DIR)\n",
    "all_metrics.append(m); all_top10.append(t)\n",
    "\n",
    "# Regularized linear\n",
    "m, t = run_logreg(X_train, y_train_enc, X_valid, y_valid_enc, X_test, y_test_enc,\n",
    "                  feature_names, class_labels, MODEL_DIR)\n",
    "all_metrics.append(m); all_top10.append(t)\n",
    "\n",
    "# SVM RBF\n",
    "m, t = run_svm_rbf(X_train, y_train_enc, X_valid, y_valid_enc, X_test, y_test_enc,\n",
    "                   feature_names, class_labels, MODEL_DIR)\n",
    "all_metrics.append(m); all_top10.append(t)\n",
    "\n",
    "print(\"All models trained and evaluated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f80fdc",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc2c3b",
   "metadata": {},
   "source": [
    "### Performance summary table (test-set metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff72ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>auc_macro</th>\n",
       "      <th>auc_weighted</th>\n",
       "      <th>kappa</th>\n",
       "      <th>best_params</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.706559</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.699596</td>\n",
       "      <td>0.561027</td>\n",
       "      <td>0.536764</td>\n",
       "      <td>0.501738</td>\n",
       "      <td>0.910977</td>\n",
       "      <td>0.926079</td>\n",
       "      <td>0.681979</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': None, 'min_...</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1;0,1,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.704030</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.700326</td>\n",
       "      <td>0.587859</td>\n",
       "      <td>0.543554</td>\n",
       "      <td>0.527868</td>\n",
       "      <td>0.908494</td>\n",
       "      <td>0.921318</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>{'n_estimators': 300, 'learning_rate': 0.1, 'm...</td>\n",
       "      <td>1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2;0,1,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.685786</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.685855</td>\n",
       "      <td>0.567439</td>\n",
       "      <td>0.526530</td>\n",
       "      <td>0.503064</td>\n",
       "      <td>0.934965</td>\n",
       "      <td>0.931771</td>\n",
       "      <td>0.666450</td>\n",
       "      <td>{'iterations': 300, 'learning_rate': 0.15, 'de...</td>\n",
       "      <td>1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1;0,1,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.698798</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.703741</td>\n",
       "      <td>0.531375</td>\n",
       "      <td>0.533884</td>\n",
       "      <td>0.504552</td>\n",
       "      <td>0.918887</td>\n",
       "      <td>0.932681</td>\n",
       "      <td>0.685111</td>\n",
       "      <td>{'penalty': 'l2', 'C': 1.0}</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,2,1;0,1,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>0.637286</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.662233</td>\n",
       "      <td>0.546109</td>\n",
       "      <td>0.498633</td>\n",
       "      <td>0.494264</td>\n",
       "      <td>0.929584</td>\n",
       "      <td>0.931599</td>\n",
       "      <td>0.662829</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale'}</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,2,1;0,1,0,0,0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  precision_weighted  recall_weighted  f1_weighted  \\\n",
       "0        RandomForest            0.706559         0.740000     0.699596   \n",
       "1             XGBoost            0.704030         0.746667     0.700326   \n",
       "2            CatBoost            0.685786         0.726667     0.685855   \n",
       "3  LogisticRegression            0.698798         0.740000     0.703741   \n",
       "4             SVM_RBF            0.637286         0.726667     0.662233   \n",
       "\n",
       "   precision_macro  recall_macro  f1_macro  auc_macro  auc_weighted     kappa  \\\n",
       "0         0.561027      0.536764  0.501738   0.910977      0.926079  0.681979   \n",
       "1         0.587859      0.543554  0.527868   0.908494      0.921318  0.690083   \n",
       "2         0.567439      0.526530  0.503064   0.934965      0.931771  0.666450   \n",
       "3         0.531375      0.533884  0.504552   0.918887      0.932681  0.685111   \n",
       "4         0.546109      0.498633  0.494264   0.929584      0.931599  0.662829   \n",
       "\n",
       "                                         best_params  \\\n",
       "0  {'n_estimators': 200, 'max_depth': None, 'min_...   \n",
       "1  {'n_estimators': 300, 'learning_rate': 0.1, 'm...   \n",
       "2  {'iterations': 300, 'learning_rate': 0.15, 'de...   \n",
       "3                        {'penalty': 'l2', 'C': 1.0}   \n",
       "4                       {'C': 1.0, 'gamma': 'scale'}   \n",
       "\n",
       "                                    confusion_matrix  \n",
       "0  0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1;0,1,0,0,0,...  \n",
       "1  1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2;0,1,0,0,0,...  \n",
       "2  1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1;0,1,0,0,0,...  \n",
       "3  0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,2,1;0,1,0,0,0,...  \n",
       "4  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,2,1;0,1,0,0,0,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten confusion matrices to strings for compact CSV; keep scores as columns\n",
    "rows = []\n",
    "for m in all_metrics:\n",
    "    row = {\n",
    "        \"model\": m.get(\"model\"),\n",
    "        \"precision_weighted\": m.get(\"precision_weighted\"),\n",
    "        \"recall_weighted\": m.get(\"recall_weighted\"),\n",
    "        \"f1_weighted\": m.get(\"f1_weighted\"),\n",
    "        \"precision_macro\": m.get(\"precision_macro\"),\n",
    "        \"recall_macro\": m.get(\"recall_macro\"),\n",
    "        \"f1_macro\": m.get(\"f1_macro\"),\n",
    "        \"auc_macro\": m.get(\"auc_macro\"),\n",
    "        \"auc_weighted\": m.get(\"auc_weighted\"),\n",
    "        \"kappa\": m.get(\"kappa\"),\n",
    "        \"best_params\": m.get(\"best_params\"),\n",
    "    }\n",
    "    cm = m.get(\"confusion_matrix\")\n",
    "    if cm is not None:\n",
    "        row[\"confusion_matrix\"] = \";\".join([\",\".join(map(str, r)) for r in cm])\n",
    "    else:\n",
    "        row[\"confusion_matrix\"] = \"\"\n",
    "    rows.append(row)\n",
    "\n",
    "perf_df = pd.DataFrame(rows)\n",
    "perf_path = os.path.join(PERF_DIR, \"performance_summary.csv\")\n",
    "perf_df.to_csv(perf_path, index=False)\n",
    "perf_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMHackathon (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
